{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naučíte se jak ve vašich Python programech vytáhnout data z webových stránek.\n",
    "\n",
    "https://kodim.cz/kurzy/python-data-1/ziskavani-dat/webscraping/html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML\n",
    "\n",
    "Webové stránky jsou textové soubory psané ve speciálním jazyce zvaném `HTML` (_HyperText Markup Language_). \n",
    "\n",
    "`HTML` není jazyk programovací, nýbrž takzvaně značkovací. \n",
    "\n",
    "Pomocí `HTML` tvůrci webů definují samotný obsah stránek, tedy texty, obrázky, odkazy apod. \n",
    "\n",
    "Samotný vzhled stránky (barvičky, styl písma, rozmístění prvků na stránce apod.) se vytváří v jazyce zvaném `CSS`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML značky (tagy)\n",
    "\n",
    "HTML elements reference:  https://developer.mozilla.org/en-US/docs/Web/HTML/Element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>Ukázka</title>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>Nadpis první úrovně</h1>\n",
    "  <p>\n",
    "    Text nějakého odstavce, který obsahuje\n",
    "    <em>zvýrazněný text</em> a také <strong>\n",
    "    důležitý text.</strong>\n",
    "  </p>\n",
    "\n",
    "  <h2>Nadpis druhé úrovně</h2>\n",
    "  <div class=\"sekce1\">\n",
    "    <p>\n",
    "      Druhý odstavec je v takzvaném divu, což je\n",
    "      značka, která nemá sama o sobě žádný význam.\n",
    "      Také zde máme\n",
    "      <a href=\"http;://www.czechitas.cz\"> odkaz na\n",
    "      stránky Czechitas</a>.\n",
    "    </p>\n",
    "\n",
    "    <ol type=\"a\">\n",
    "      <li>První položka seznamu</li>\n",
    "      <li>Druhá položka seznamu</li>\n",
    "      <li>Třetí položka seznamu</li>\n",
    "    </ol>\n",
    "  </div>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>Ukázka</title>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>Nadpis první úrovně</h1>\n",
    "  <p>\n",
    "    Text nějakého odstavce, který obsahuje\n",
    "    <em>zvýrazněný text</em> a také <strong>\n",
    "    důležitý text.</strong>\n",
    "  </p>\n",
    "\n",
    "  <h2>Nadpis druhé úrovně</h2>\n",
    "  <div class=\"sekce1\">\n",
    "    <p>\n",
    "      Druhý odstavec je v takzvaném divu, což je\n",
    "      značka, která nemá sama o sobě žádný význam.\n",
    "      Také zde máme\n",
    "      <a href=\"http;://www.czechitas.cz\"> odkaz na\n",
    "      stránky Czechitas</a>.\n",
    "    </p>\n",
    "\n",
    "   <ol type=a>\n",
    "      <li>První položka seznamu</li>\n",
    "      <li>Druhá položka seznamu</li>\n",
    "      <li>Třetí položka seznamu</li>\n",
    "    </ol>\n",
    "  </div>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping v Pythonu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potřebujeme nainstalovat modul, který umí číst HTML značky a pomocí těchto značek v HTML souborech vyhledávat. \n",
    "\n",
    "`pip3 install requests-html`\n",
    "\n",
    "`pip install requests-html # pro Windows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install requests-html\n",
    "\n",
    "from requests_html import HTML\n",
    "\n",
    "# obsah textového souboru už do proměnné načíst umíme\n",
    "with open(\"assets/dhmo/ukazka-html/ukazka.html\", encoding=\"utf-8\") as soubor:\n",
    "    obsah = soubor.read()\n",
    "\n",
    "# použijeme náš nový modul, aby si tento obsah přečetl a umožnil v něm vyhledávat\n",
    "html = HTML(html=obsah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML značky můžeme vyhledávat podle jména. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text nějakého odstavce, který obsahuje zvýrazněný text a také důležitý text.\n",
      "Druhý odstavec je v takzvaném divu, což je značka, která nemá sama o sobě žádný význam. Také zde máme odkaz na stránky Czechitas.\n"
     ]
    }
   ],
   "source": [
    "for odstavec in html.find(\"p\"):\n",
    "    print(odstavec.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Můžeme vyhledávání podle třídy (atribut class). Třídy se vyhledávají tak, že jejich název začneme tečkou.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Druhý odstavec je v takzvaném divu, což je značka, která nemá sama o sobě žádný význam. Také zde máme odkaz na stránky Czechitas.\n",
      "První položka seznamu\n",
      "Druhá položka seznamu\n",
      "Třetí položka seznamu\n"
     ]
    }
   ],
   "source": [
    "for i in html.find(\".sekce1\"):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Můžeme přistupovat k atributům nalezených značek. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.czechitas.cz\n"
     ]
    }
   ],
   "source": [
    "# najít adresy všech odkazů na naší stránce.\n",
    "for odkaz in html.find(\"a\"):\n",
    "    print(odkaz.attrs[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Složitější pravidla vyhledávání"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Můžeme vyhledávat podle více značek najednou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nadpis první úrovně\n",
      "Nadpis druhé úrovně\n"
     ]
    }
   ],
   "source": [
    "for nadpis in html.find(\"h1, h2\"):\n",
    "    print(nadpis.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Můžeme vyhledávat podle atributů. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'ol' type='a'>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# najít všechny seznamy, kde atribut type je roven a.\n",
    "\n",
    "html.find('ol[type=\"a\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Můžeme vyhledávat podle zanoření. \n",
    "\n",
    "Mezera ve vyhledávacím řetězci znamená libovolně hluboké zanoření. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "XPathExpr.join() got an unexpected keyword argument 'closing_combiner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# najít všechny odstavce, které jsou uvnitř značky s třídou sekce1\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m html\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.sekce1 p\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests_html.py:212\u001b[0m, in \u001b[0;36mBaseParser.find\u001b[0;34m(self, selector, containing, clean, first, _encoding)\u001b[0m\n\u001b[1;32m    207\u001b[0m     containing \u001b[38;5;241m=\u001b[39m [containing]\n\u001b[1;32m    209\u001b[0m encoding \u001b[38;5;241m=\u001b[39m _encoding \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding\n\u001b[1;32m    210\u001b[0m elements \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    211\u001b[0m     Element(element\u001b[38;5;241m=\u001b[39mfound, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, default_encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m found \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpq(selector)\n\u001b[1;32m    213\u001b[0m ]\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m containing:\n\u001b[1;32m    216\u001b[0m     elements_copy \u001b[38;5;241m=\u001b[39m elements\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyquery/pyquery.py:256\u001b[0m, in \u001b[0;36mPyQuery.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    255\u001b[0m     args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m,)\n\u001b[0;32m--> 256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copy(\u001b[38;5;241m*\u001b[39margs, parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyquery/pyquery.py:242\u001b[0m, in \u001b[0;36mPyQuery._copy\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    241\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespaces\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamespaces)\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyquery/pyquery.py:227\u001b[0m, in \u001b[0;36mPyQuery.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# select nodes\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m elements \u001b[38;5;129;01mand\u001b[39;00m selector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_default:\n\u001b[0;32m--> 227\u001b[0m     xpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_css_to_xpath(selector)\n\u001b[1;32m    228\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m elements:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyquery/pyquery.py:238\u001b[0m, in \u001b[0;36mPyQuery._css_to_xpath\u001b[0;34m(self, selector, prefix)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_css_to_xpath\u001b[39m(\u001b[38;5;28mself\u001b[39m, selector, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescendant-or-self::\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    237\u001b[0m     selector \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[@\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_translator\u001b[38;5;241m.\u001b[39mcss_to_xpath(selector, prefix)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cssselect/xpath.py:190\u001b[0m, in \u001b[0;36mGenericTranslator.css_to_xpath\u001b[0;34m(self, css, prefix)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcss_to_xpath\u001b[39m(\u001b[38;5;28mself\u001b[39m, css, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescendant-or-self::\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Translate a *group of selectors* to XPath.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    Pseudo-elements are not supported here since XPath only knows\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselector_to_xpath(selector, prefix,\n\u001b[1;32m    191\u001b[0m                                              translate_pseudo_elements\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    192\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m selector \u001b[38;5;129;01min\u001b[39;00m parse(css))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cssselect/xpath.py:190\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcss_to_xpath\u001b[39m(\u001b[38;5;28mself\u001b[39m, css, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescendant-or-self::\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Translate a *group of selectors* to XPath.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    Pseudo-elements are not supported here since XPath only knows\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselector_to_xpath(selector, prefix,\n\u001b[1;32m    191\u001b[0m                                              translate_pseudo_elements\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    192\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m selector \u001b[38;5;129;01min\u001b[39;00m parse(css))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cssselect/xpath.py:219\u001b[0m, in \u001b[0;36mGenericTranslator.selector_to_xpath\u001b[0;34m(self, selector, prefix, translate_pseudo_elements)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected a parsed selector, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (selector,))\n\u001b[0;32m--> 219\u001b[0m xpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxpath(tree)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(xpath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxpathexpr_cls)  \u001b[38;5;66;03m# help debug a missing 'return'\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m translate_pseudo_elements \u001b[38;5;129;01mand\u001b[39;00m selector\u001b[38;5;241m.\u001b[39mpseudo_element:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cssselect/xpath.py:254\u001b[0m, in \u001b[0;36mGenericTranslator.xpath\u001b[0;34m(self, parsed_selector)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExpressionError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m  type_name)\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(parsed_selector)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cssselect/xpath.py:263\u001b[0m, in \u001b[0;36mGenericTranslator.xpath_combinedselector\u001b[0;34m(self, combined)\u001b[0m\n\u001b[1;32m    261\u001b[0m combinator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombinator_mapping[combined\u001b[38;5;241m.\u001b[39mcombinator]\n\u001b[1;32m    262\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxpath_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_combinator\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m combinator)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxpath(combined\u001b[38;5;241m.\u001b[39mselector),\n\u001b[1;32m    264\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxpath(combined\u001b[38;5;241m.\u001b[39msubselector))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cssselect/xpath.py:356\u001b[0m, in \u001b[0;36mGenericTranslator.xpath_descendant_combinator\u001b[0;34m(self, left, right)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mxpath_descendant_combinator\u001b[39m(\u001b[38;5;28mself\u001b[39m, left, right):\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"right is a child, grand-child or further descendant of left\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m left\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/descendant-or-self::*/\u001b[39m\u001b[38;5;124m'\u001b[39m, right)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyquery/cssselectpatch.py:34\u001b[0m, in \u001b[0;36mXPathExpr.join\u001b[0;34m(self, combiner, other, closing_combiner, has_inner_condition)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, combiner, other,\n\u001b[1;32m     33\u001b[0m          closing_combiner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, has_inner_condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 34\u001b[0m     res \u001b[38;5;241m=\u001b[39m XPathExprOrig\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m, combiner, other,\n\u001b[1;32m     35\u001b[0m                              closing_combiner\u001b[38;5;241m=\u001b[39mclosing_combiner,\n\u001b[1;32m     36\u001b[0m                              has_inner_condition\u001b[38;5;241m=\u001b[39mhas_inner_condition)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_condition \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mpost_condition\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mTypeError\u001b[0m: XPathExpr.join() got an unexpected keyword argument 'closing_combiner'"
     ]
    }
   ],
   "source": [
    "# najít všechny odstavce, které jsou uvnitř značky s třídou sekce1\n",
    "\n",
    "html.find(\".sekce1 p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'p' >]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pokud bychom chtěli pouze odstavce, které jsou přímým potomkem značky s třídou sekce1,\n",
    "# použijeme symbol zobáčku.\n",
    "\n",
    "html.find(\".sekce1 > p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'li' >, <Element 'li' >, <Element 'li' >]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pokud tyto techniky zkombinujeme,\n",
    "# můžeme například najít všechny položky (<li>) ve všech seznamech (<ol>),\n",
    "# jejichž atribut type je roven a.\n",
    "\n",
    "html.find('ol[type=\"a\"] li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping přes internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na adrese https://apps.kodim.cz/python-data/scrape najdete naši malou ukázkovou stránku z úvodu. \n",
    "\n",
    "\n",
    "Na adrese https://apps.kodim.cz/python-data/dhmo najdete také finální verzi stránky šířící poplach ohledně DHMO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text nějakého odstavce, který obsahuje zvýrazněný text a také důležitý text.\n",
      "Druhý odstavec je v takzvaném divu, což je značka, která nemá sama o sobě žádný význam. Také zde máme odkaz na stránky Czechitas.\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "stranka = session.get(\"https://apps.kodim.cz/python-data/scrape\")\n",
    "for odstavec in stranka.html.find(\"p\"):\n",
    "    print(odstavec.text)\n",
    "\n",
    "# session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud chcete vidět celý stažený zdrojový kód stránky jako text, napište:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "  <meta charset=\"UTF-8\">\n",
      "  <title>Ukázka</title>\n",
      "</head>\n",
      "<body>\n",
      "  <h1>Nadpis první úrovně</h1>\n",
      "  <p>Text nějakého odstavce, který obsahuje <em>zvýrazněný text</em> a také  <strong>důležitý text.</strong></p>\n",
      "\n",
      "  <h2>Nadpis druhé úrovně</h2>\n",
      "  <div class=\"sekce1\">\n",
      "    <p>Druhý odstavec je v takzvaném divu, což je značka, která nemá sama o sobě žádný význam. Také zde máme <a href=\"https://www.czechitas.cz/\">odkaz na stránky Czechitas</a>.</p>\n",
      "\n",
      "    <ol type=\"a\">\n",
      "      <li>První položka seznamu</li>\n",
      "      <li>Druhá položka seznamu</li>\n",
      "      <li>Třetí položka seznamu</li>\n",
      "    </ol>\n",
      "  </div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(stranka.html.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping vs JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velkým trendem v dnešní době je nepsat HTML kód stránky přímo, jako jsme to viděli výše. \n",
    "\n",
    "Místo toho se použije jazyk JavaScript, který kód stránky sám vygeneruje. \n",
    "\n",
    "Tím může být stránka mnohem flexibilnější a interaktivnější, což je hezké pro uživatele. \n",
    "\n",
    "Pro nás to však znamená, že když stránku stahujeme v Pythonu, neobdržíme značky HTML, ale JavaScriptový program. \n",
    "\n",
    "Ten nejdříve musíme v Pythonu spustit a nechat si výsledné HTML vygenerovat.\n",
    "\n",
    "Podívejte se například na tuto stránku, která je psána přesně tímto způsobem. \n",
    "\n",
    "https://react-shopping-cart-67954.firebaseapp.com/\n",
    "\n",
    "Pokud chceme takovou stránku scrapovat, musíme použít takovýto kód.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/entiaperse/Documents/GitHub/czechitas-kodim-cz/python-pro-data-1/02-ziskavani-dat/01-web-scraping/web-scraping.ipynb Cell 32\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/entiaperse/Documents/GitHub/czechitas-kodim-cz/python-pro-data-1/02-ziskavani-dat/01-web-scraping/web-scraping.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m session \u001b[39m=\u001b[39m HTMLSession()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/entiaperse/Documents/GitHub/czechitas-kodim-cz/python-pro-data-1/02-ziskavani-dat/01-web-scraping/web-scraping.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m stranka \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mhttps://react-shopping-cart-67954.firebaseapp.com/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/entiaperse/Documents/GitHub/czechitas-kodim-cz/python-pro-data-1/02-ziskavani-dat/01-web-scraping/web-scraping.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m stranka\u001b[39m.\u001b[39;49mhtml\u001b[39m.\u001b[39;49mrender(sleep\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/entiaperse/Documents/GitHub/czechitas-kodim-cz/python-pro-data-1/02-ziskavani-dat/01-web-scraping/web-scraping.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(stranka.html.html)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/entiaperse/Documents/GitHub/czechitas-kodim-cz/python-pro-data-1/02-ziskavani-dat/01-web-scraping/web-scraping.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/entiaperse/Documents/GitHub/czechitas-kodim-cz/python-pro-data-1/02-ziskavani-dat/01-web-scraping/web-scraping.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# session.close()\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests_html.py:586\u001b[0m, in \u001b[0;36mHTML.render\u001b[0;34m(self, retries, script, wait, scrolldown, sleep, reload, timeout, keep_page)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, retries: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m, script: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, wait: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, scrolldown\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, sleep: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, reload: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, timeout: Union[\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m8.0\u001b[39m, keep_page: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    542\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Reloads the response in Chromium, and replaces HTML content\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m    with an updated version, with JavaScript executed.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39m    Chromium into your home directory (``~/.pyppeteer``).\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbrowser \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mbrowser  \u001b[39m# Automatically create a event loop and browser\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    589\u001b[0m     \u001b[39m# Automatically set Reload to False, if example URL is being used.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests_html.py:729\u001b[0m, in \u001b[0;36mHTMLSession.browser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloop \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_event_loop()\n\u001b[1;32m    728\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloop\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 729\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    730\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_browser \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloop\u001b[39m.\u001b[39mrun_until_complete(\u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mbrowser)\n\u001b[1;32m    731\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_browser\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "stranka = session.get(\"https://react-shopping-cart-67954.firebaseapp.com/\")\n",
    "stranka.html.render(sleep=5)\n",
    "\n",
    "# print(stranka.html.html)\n",
    "\n",
    "# session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- https://pypi.org/project/beautifulsoup4/\n",
    "- https://pypi.org/project/requests/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
